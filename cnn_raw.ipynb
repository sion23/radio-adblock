{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02cfb3b5-c82c-4f25-bcc6-51f27d6a0c86",
   "metadata": {},
   "source": [
    "# Convolution Neural Network with raw audio data\n",
    "\n",
    "\n",
    "Assumes that preprocessing step is already done using the matlab functions (output is table which we will convert to pandas dataframe)\n",
    "* `generate_data.m`\n",
    "* `resampleRun.m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47bc697d-515a-472c-ba5c-0172da761e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5671bd8b-6c6e-4f31-92c7-53912d023d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "dataLength = 5 # in seconds\n",
    "filename  = \"raw_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd08a0f-8e13-4f74-bba9-aebdd0f8fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(filename, dataLength):\n",
    "    data_raw = pd.read_csv(filename)\n",
    "    numSamples = data_raw.shape[0]\n",
    "    sampleRate = data_raw.iloc[0].iloc[1]\n",
    "    labels = []\n",
    "    mfcc_spectrograms = np.empty((numSamples//10, dataLength*sampleRate), dtype=np.float32)  # Preallocate array\n",
    "    for index, row in data_raw.iterrows():\n",
    "        if index%10 == 0:\n",
    "            if row.iloc[0] == 'ad':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "            data = row[2:].values\n",
    "            data_signals[index//10] = data\n",
    "    labels = np.array(labels)\n",
    "    return labels, data_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced2b7e9-c72d-4b4a-b172-4f861f90270e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_signals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load up mfcc data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m labels, raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataLength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(raw_data\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mload_raw_data\u001b[0;34m(filename, dataLength)\u001b[0m\n\u001b[1;32m     12\u001b[0m             labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m         data \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m---> 14\u001b[0m         \u001b[43mdata_signals\u001b[49m[index\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     15\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, data_signals\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_signals' is not defined"
     ]
    }
   ],
   "source": [
    "# load up mfcc data\n",
    "labels, raw_data = load_raw_data(filename, dataLength)\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e573be6-88ad-48e6-a749-7f1a61970172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batchSize = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f25232e6-768e-432e-8daf-62b4f8e53510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor compliant dataset\n",
    "raw_train, raw_test, labels_train, labels_test = train_test_split(raw_data, labels, test_size=0.2, random_state=100)\n",
    "raw_train_tensor  = torch.tensor(raw_train).unsqueeze(1)\n",
    "raw_test_tensor   = torch.tensor(raw_test).unsqueeze(1)\n",
    "labels_train_tensor = torch.tensor(labels_train)\n",
    "labels_test_tensor  = torch.tensor(labels_test)\n",
    "train_dataset = TensorDataset(raw_train_tensor, labels_train_tensor)\n",
    "test_dataset = TensorDataset(raw_test_tensor, labels_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batchSize, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batchSize, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5c9bc9-f954-4c18-a066-58c97ede5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(7936, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 498, 12) #(batch size, channels, height, width)\n",
    "        # Convolutional layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten the output for fully connected layers\n",
    "        size = x.size()[1:]  #all size except batchSize\n",
    "        numFeatures = 1\n",
    "        for s in size:\n",
    "            numFeatures *= s\n",
    "        x = x.view(-1, numFeatures)\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf612cc-276c-4547-bef2-4b46f45c1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Model\n",
    "model = CNN()\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73686e1-564b-428d-a08d-ddd9de541563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [1/10], Loss: 0.4242\n",
      "Epoch [2/10], Loss: 0.2097\n",
      "Epoch [3/10], Loss: 0.1540\n",
      "Epoch [4/10], Loss: 0.1167\n",
      "Epoch [5/10], Loss: 0.1102\n",
      "Epoch [6/10], Loss: 0.1015\n",
      "Epoch [7/10], Loss: 0.0927\n",
      "Epoch [8/10], Loss: 0.0568\n",
      "Epoch [9/10], Loss: 0.1050\n",
      "Epoch [10/10], Loss: 0.0453\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8765fdca-df0a-4a1f-ab8f-954aeb38d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1ba8f-6474-4c65-ac8e-15b18211106d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
