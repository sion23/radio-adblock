{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02cfb3b5-c82c-4f25-bcc6-51f27d6a0c86",
   "metadata": {},
   "source": [
    "# Convolution Neural Network with raw audio data\n",
    "\n",
    "* `read-write-data.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47bc697d-515a-472c-ba5c-0172da761e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced2b7e9-c72d-4b4a-b172-4f861f90270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "(1049,)\n",
      "(1049, 220500)\n"
     ]
    }
   ],
   "source": [
    "# load up mfcc data\n",
    "#labels, raw_data = load_raw_data_dask(labelFilename, dataFilename, dataLength)\n",
    "raw_labels = np.load(\"labels.npy\") \n",
    "raw_data = np.load(\"raw_data.npy\")\n",
    "print(raw_labels)\n",
    "print(raw_labels.shape)\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25232e6-768e-432e-8daf-62b4f8e53510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor compliant dataset\n",
    "batchSize = 100\n",
    "raw_train, raw_test, labels_train, labels_test = train_test_split(raw_data, raw_labels, test_size=0.2, random_state=100)\n",
    "\n",
    "raw_train_tensor    = torch.tensor(raw_train).unsqueeze(1)\n",
    "raw_test_tensor     = torch.tensor(raw_test).unsqueeze(1)\n",
    "labels_train_tensor = torch.tensor(labels_train)\n",
    "labels_test_tensor  = torch.tensor(labels_test)\n",
    "\n",
    "train_dataset = TensorDataset(raw_train_tensor, labels_train_tensor)\n",
    "test_dataset  = TensorDataset(raw_test_tensor, labels_test_tensor)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size = batchSize, shuffle = True)\n",
    "test_loader   = DataLoader(test_dataset, batch_size = batchSize, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5c9bc9-f954-4c18-a066-58c97ede5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(1,  32,  kernel_size=10, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64,  kernel_size=5, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.AvgPool1d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(3527808, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten the output for fully connected layers\n",
    "        size = x.size()[1:]  #all size except batchSize\n",
    "        numFeatures = 1\n",
    "        for s in size:\n",
    "            numFeatures *= s\n",
    "        x = x.view(-1, numFeatures)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf612cc-276c-4547-bef2-4b46f45c1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Model\n",
    "model = CNN()\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73686e1-564b-428d-a08d-ddd9de541563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 30.7335\n",
      "Epoch [2/5], Loss: 0.3124\n",
      "Epoch [3/5], Loss: 0.2495\n",
      "Epoch [4/5], Loss: 0.1906\n",
      "Epoch [5/5], Loss: 0.1435\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8765fdca-df0a-4a1f-ab8f-954aeb38d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9095238095238095\n",
      "Test Precision: 0.9223300970873787\n",
      "F1: 0.9090909090909091\n",
      "Recall: 0.8962264150943396\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "totalLabels    = []\n",
    "totalPredicted = []\n",
    "with torch.no_grad():\n",
    "    for t_inputs, t_labels in test_loader:\n",
    "        outputs = model(t_inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        totalLabels    += t_labels\n",
    "        totalPredicted += predicted\n",
    "print(f\"Test Accuracy: {accuracy_score(totalLabels, totalPredicted)}\")\n",
    "print(f\"Test Precision: {precision_score(totalLabels, totalPredicted)}\")\n",
    "print(f\"F1: {f1_score(totalLabels, totalPredicted)}\")\n",
    "print(f\"Recall: {recall_score(totalLabels, totalPredicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cfc0a41-3693-49fe-88af-82585d7dab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cnn_raw_model_batch_100_epoch_5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb0760-a174-47e3-a6f8-b272b9d607f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
