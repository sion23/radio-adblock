{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e5a7f4-a727-4f0d-be4b-a7700613e40e",
   "metadata": {},
   "source": [
    "# Convolution Neural Network with MFCC + delta + delta-delta features\n",
    "Used to generate and save a Convolutional Nueral Network model that utilizes extracted mfcc features in addition to the delta and delta-delta features of the mfccs.\n",
    "\n",
    "Requires data from:\n",
    "* `generate_data_py.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47bc697d-515a-472c-ba5c-0172da761e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced2b7e9-c72d-4b4a-b172-4f861f90270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1049,)\n",
      "(1049, 3, 431, 12)\n"
     ]
    }
   ],
   "source": [
    "# load up mfcc + delta data\n",
    "mfcc_labels = np.load(os.path.join(\"data\", \"labels.npy\"))\n",
    "mfcc_data   = np.load(os.path.join(\"data\", \"mfcc_delta_data.npy\"))\n",
    "print(mfcc_labels.shape)\n",
    "print(mfcc_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25232e6-768e-432e-8daf-62b4f8e53510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([839, 3, 431, 12])\n"
     ]
    }
   ],
   "source": [
    "# Convert data to tensor compliant dataset\n",
    "batchSize = 30;\n",
    "mfccs_train, mfccs_test, labels_train, labels_test = train_test_split(mfcc_data, mfcc_labels, test_size=0.2, random_state=100)\n",
    "\n",
    "mfccs_train_tensor  = torch.tensor(mfccs_train)\n",
    "mfccs_test_tensor   = torch.tensor(mfccs_test)\n",
    "labels_train_tensor = torch.tensor(labels_train)\n",
    "labels_test_tensor  = torch.tensor(labels_test)\n",
    "\n",
    "print(mfccs_train_tensor.shape)\n",
    "\n",
    "train_dataset = TensorDataset(mfccs_train_tensor, labels_train_tensor)\n",
    "test_dataset  = TensorDataset(mfccs_test_tensor, labels_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batchSize, shuffle = True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size = batchSize, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5c9bc9-f954-4c18-a066-58c97ede5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(6784, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten the output into a 1D vector for use in the fully connected layers\n",
    "        size = x.size()[1:]  #all size except batchSize\n",
    "        numFeatures = 1\n",
    "        for s in size:\n",
    "            numFeatures *= s\n",
    "        x = x.view(-1, numFeatures)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf612cc-276c-4547-bef2-4b46f45c1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Model\n",
    "model = CNN()\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73686e1-564b-428d-a08d-ddd9de541563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 3.8233\n",
      "Epoch [2/10], Loss: 0.2742\n",
      "Epoch [3/10], Loss: 0.2740\n",
      "Epoch [4/10], Loss: 0.1967\n",
      "Epoch [5/10], Loss: 0.1176\n",
      "Epoch [6/10], Loss: 0.1156\n",
      "Epoch [7/10], Loss: 0.0804\n",
      "Epoch [8/10], Loss: 0.0735\n",
      "Epoch [9/10], Loss: 0.0873\n",
      "Epoch [10/10], Loss: 0.0577\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8765fdca-df0a-4a1f-ab8f-954aeb38d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9476190476190476\n",
      "Test Precision: 0.9279279279279279\n",
      "F1: 0.9493087557603687\n",
      "Recall: 0.9716981132075472\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model.eval()\n",
    "totalLabels = []\n",
    "totalPredicted = []\n",
    "with torch.no_grad():\n",
    "    for t_inputs, t_labels in test_loader:\n",
    "        outputs = model(t_inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        totalLabels += t_labels\n",
    "        totalPredicted += predicted\n",
    "print(f\"Test Accuracy: {accuracy_score(totalLabels, totalPredicted)}\")\n",
    "print(f\"Test Precision: {precision_score(totalLabels, totalPredicted)}\")\n",
    "print(f\"F1: {f1_score(totalLabels, totalPredicted)}\")\n",
    "print(f\"Recall: {recall_score(totalLabels, totalPredicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827d6b77-351f-497d-96b0-f272556fe354",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_mfcc_delta_model_testing.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "torch.save(model.state_dict(), os.path.join(\"models\", \"cnn_mfcc_delta_model_testing.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c52d4-1cc7-473b-9a10-4572fd08ec08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
